{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576c800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n",
      "CPU times: user 45.3 ms, sys: 6.62 ms, total: 52 ms\n",
      "Wall time: 56.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Text processing\n",
    "import emoji\n",
    "from textblob import TextBlob\n",
    "import contractions\n",
    "\n",
    "# Feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef783996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspaces/CivicSense/data/TwitterSentimentAnalysisDataset/raw/twitter_training.csv')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "NOTEBOOK_DIR  = Path().resolve()\n",
    "BASE_DIR = NOTEBOOK_DIR.parent\n",
    "DATASET_DIR = BASE_DIR /  \"data\" / 'TwitterSentimentAnalysisDataset' \n",
    "DATASET_FILE_PATH = DATASET_DIR / \"raw\" / 'twitter_training.csv'\n",
    "DATASET_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1eb7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (74681, 4)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72235</th>\n",
       "      <td>11176</td>\n",
       "      <td>TomClancysGhostRecon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Good morning and good night from Auroa!... @ U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62622</th>\n",
       "      <td>5135</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>@ G2A _ com ur site is trash. Search for GTA V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52394</th>\n",
       "      <td>10600</td>\n",
       "      <td>RedDeadRedemption(RDR)</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I won the Star Raider achievement in Red Pill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10558</th>\n",
       "      <td>13016</td>\n",
       "      <td>Xbox(Xseries)</td>\n",
       "      <td>Negative</td>\n",
       "      <td>A revolutionary body form factor for new gamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72432</th>\n",
       "      <td>8809</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Latest The GST Daily! paper.li / GKConsultants...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id                  entity   sentiment  \\\n",
       "72235     11176    TomClancysGhostRecon     Neutral   \n",
       "62622      5135     GrandTheftAuto(GTA)  Irrelevant   \n",
       "52394     10600  RedDeadRedemption(RDR)    Positive   \n",
       "10558     13016           Xbox(Xseries)    Negative   \n",
       "72432      8809                  Nvidia     Neutral   \n",
       "\n",
       "                                           tweet_content  \n",
       "72235  Good morning and good night from Auroa!... @ U...  \n",
       "62622  @ G2A _ com ur site is trash. Search for GTA V...  \n",
       "52394  I won the Star Raider achievement in Red Pill ...  \n",
       "10558  A revolutionary body form factor for new gamin...  \n",
       "72432  Latest The GST Daily! paper.li / GKConsultants...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(str(DATASET_FILE_PATH))\n",
    "df.columns = ['tweet_id', 'entity', 'sentiment', 'tweet_content']\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "731862bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASIC DATA UNDERSTANDING\n",
      "================================================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74681 entries, 0 to 74680\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tweet_id       74681 non-null  int64 \n",
      " 1   entity         74681 non-null  object\n",
      " 2   sentiment      74681 non-null  object\n",
      " 3   tweet_content  73995 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "            tweet_id     entity sentiment tweet_content\n",
      "count   74681.000000      74681     74681         73995\n",
      "unique           NaN         32         4         69490\n",
      "top              NaN  Microsoft  Negative              \n",
      "freq             NaN       2400     22542           172\n",
      "mean     6432.640149        NaN       NaN           NaN\n",
      "std      3740.423819        NaN       NaN           NaN\n",
      "min         1.000000        NaN       NaN           NaN\n",
      "25%      3195.000000        NaN       NaN           NaN\n",
      "50%      6422.000000        NaN       NaN           NaN\n",
      "75%      9601.000000        NaN       NaN           NaN\n",
      "max     13200.000000        NaN       NaN           NaN\n",
      "\n",
      "Missing Values:\n",
      "tweet_id           0\n",
      "entity             0\n",
      "sentiment          0\n",
      "tweet_content    686\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 2700\n"
     ]
    }
   ],
   "source": [
    "print(\"BASIC DATA UNDERSTANDING\")\n",
    "print(\"=\"*80)\n",
    "# Dataset info\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe(include='all'))\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc09e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
